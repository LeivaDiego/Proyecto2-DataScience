{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import pydicom as dicom\n",
    "from typing import List\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader size: 436\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid ndarray.dtype 'uint16' for color space conversion, must be 'uint8' or an equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 117\u001b[0m\n\u001b[0;32m    115\u001b[0m effnet_models \u001b[38;5;241m=\u001b[39m [load_model(EffnetModel(), name, EFFNET_CHECKPOINTS_PATH)\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m MODEL_NAMES]\n\u001b[0;32m    116\u001b[0m patient_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train_images/1.2.826.0.1.3680043.14\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 117\u001b[0m df_patient_final \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_single_patient\u001b[49m\u001b[43m(\u001b[49m\u001b[43meffnet_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Mostrar el resultado\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_patient_final)\n",
      "Cell \u001b[1;32mIn[2], line 104\u001b[0m, in \u001b[0;36mpredict_single_patient\u001b[1;34m(models, patient_path)\u001b[0m\n\u001b[0;32m    101\u001b[0m df_patient_slices \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(slices, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStudyInstanceUID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlice\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlice\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m ds_patient \u001b[38;5;241m=\u001b[39m EffnetDataSet(df_patient_slices, patient_path, WEIGHTS)\n\u001b[1;32m--> 104\u001b[0m effnet_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_effnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_patient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m df_effnet_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39meffnet_pred, columns\u001b[38;5;241m=\u001b[39mFRAC_COLS \u001b[38;5;241m+\u001b[39m VERT_COLS)\n\u001b[0;32m    107\u001b[0m df_patient_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_patient_slices, df_effnet_pred], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 79\u001b[0m, in \u001b[0;36mpredict_effnet\u001b[1;34m(models, ds)\u001b[0m\n\u001b[0;32m     77\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdl_test\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicting batch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m, in \u001b[0;36mEffnetDataSet.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m     41\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[i]\u001b[38;5;241m.\u001b[39mSlice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dcm\u001b[39m\u001b[38;5;124m'\u001b[39m)        \n\u001b[1;32m---> 42\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_dicom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     43\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(img, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Convertir a (channels, height, width)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms(torch\u001b[38;5;241m.\u001b[39mas_tensor(img)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;28;01melse\u001b[39;00m img\n",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m, in \u001b[0;36mload_dicom\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     23\u001b[0m img \u001b[38;5;241m=\u001b[39m dicom\u001b[38;5;241m.\u001b[39mdcmread(path)\n\u001b[0;32m     24\u001b[0m img\u001b[38;5;241m.\u001b[39mPhotometricInterpretation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYBR_FULL\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 25\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_array\u001b[49m\n\u001b[0;32m     26\u001b[0m data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(data)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\dataset.py:2193\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpixel_array\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \n\u001b[0;32m   2137\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;124;03m        that iterates through the image frames.\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2193\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_pixel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array)\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\dataset.py:1726\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[1;34m(self, handler_name)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_pdh\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;66;03m# Use 'pydicom.pixels' backend\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m     opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoding_plugin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m-> 1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array \u001b[38;5;241m=\u001b[39m \u001b[43mpixel_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_id \u001b[38;5;241m=\u001b[39m get_image_pixel_ids(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1729\u001b[0m     \u001b[38;5;66;03m# Use 'pydicom.pixel_data_handlers' backend\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\pixels\\utils.py:1430\u001b[0m, in \u001b[0;36mpixel_array\u001b[1;34m(src, ds_out, specific_tags, index, raw, decoding_plugin, **kwargs)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1425\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to decode the pixel data as a (0002,0010) \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer Syntax \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1426\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUID\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m value of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtsyntax\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1427\u001b[0m         )\n\u001b[0;32m   1429\u001b[0m     opts \u001b[38;5;241m=\u001b[39m as_pixel_options(ds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoding_plugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoding_plugin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1439\u001b[0m f: BinaryIO\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(src, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\pixels\\decoders\\base.py:1011\u001b[0m, in \u001b[0;36mDecoder.as_array\u001b[1;34m(self, src, index, validate, raw, decoding_plugin, **kwargs)\u001b[0m\n\u001b[0;32m   1007\u001b[0m overrides: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;66;03m# Processing may give us a new writeable array anyway, so do\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m#   it first to avoid an unnecessary ndarray.copy()\u001b[39;00m\n\u001b[1;32m-> 1011\u001b[0m     arr, overrides \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;129;01mand\u001b[39;00m as_writeable \u001b[38;5;28;01melse\u001b[39;00m arr\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# Multi-sample arrays are always returned *Planar Configuration* 0\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\pixels\\decoders\\base.py:570\u001b[0m, in \u001b[0;36mDecodeRunner.process\u001b[1;34m(self, arr)\u001b[0m\n\u001b[0;32m    568\u001b[0m changes: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m PROCESSORS:\n\u001b[1;32m--> 570\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchanges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr, changes\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\pixels\\decoders\\base.py:136\u001b[0m, in \u001b[0;36m_process_color_space\u001b[1;34m(arr, runner, changes)\u001b[0m\n\u001b[0;32m    134\u001b[0m     changes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphotometric_interpretation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m PI\u001b[38;5;241m.\u001b[39mYBR_FULL\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m to_rgb:\n\u001b[1;32m--> 136\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_color_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mYBR_FULL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     changes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphotometric_interpretation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m PI\u001b[38;5;241m.\u001b[39mRGB\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\diego\\miniconda3\\envs\\DataSci_RSNA\\Lib\\site-packages\\pydicom\\pixels\\processing.py:864\u001b[0m, in \u001b[0;36mconvert_color_space\u001b[1;34m(arr, current, desired, per_frame)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert the image(s) in `arr` from one color space to another.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \n\u001b[0;32m    824\u001b[0m \u001b[38;5;124;03m.. versionchanged:: 2.2\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m  Section 7\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid ndarray.dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for color space conversion, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or an equivalent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_change\u001b[39m(arr: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid ndarray.dtype 'uint16' for color space conversion, must be 'uint8' or an equivalent"
     ]
    }
   ],
   "source": [
    "# Configuración de dispositivo\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 1  # Batch pequeño para procesamiento de un solo paciente\n",
    "\n",
    "# Configuración de modelos y paths\n",
    "WEIGHTS = T.Compose([T.ToTensor(), T.Resize((224, 224))])  # Reemplaza con WEIGHTS.transforms() si es necesario\n",
    "EFFNET_CHECKPOINTS_PATH = \"models\"  # Reemplaza con la ruta correcta\n",
    "\n",
    "# Lista de nombres de modelos\n",
    "MODEL_NAMES = [f'effnetv2-f{i}' for i in range(5)]\n",
    "FRAC_COLS = [f'C{i}_effnet_frac' for i in range(1, 8)]\n",
    "VERT_COLS = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "columns_to_transform = ['patient_overall'] + [f'C{i}' for i in range(1, 8)]\n",
    "\n",
    "# Función para cargar modelos\n",
    "def load_model(model, name, path='.') -> torch.nn.Module:\n",
    "    data = torch.load(os.path.join(path, f'{name}.tph'), map_location=DEVICE, weights_only=True)\n",
    "    model.load_state_dict(data)\n",
    "    return model\n",
    "\n",
    "# Cargar imagen DICOM\n",
    "def load_dicom(path):\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return cv2.cvtColor(data, cv2.COLOR_GRAY2RGB), img\n",
    "\n",
    "# Dataset personalizado para EfficientNet\n",
    "class EffnetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        path = os.path.join(self.path, f'{self.df.iloc[i].Slice}.dcm')        \n",
    "        img = load_dicom(path)[0]\n",
    "        img = np.transpose(img, (2, 0, 1))  # Convertir a (channels, height, width)\n",
    "        img = self.transforms(torch.as_tensor(img)) if self.transforms else img\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Definición del modelo EfficientNet para predicción\n",
    "class EffnetModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        effnet = efficientnet_v2_s()\n",
    "        self.model = create_feature_extractor(effnet, {'flatten': 'flatten'})\n",
    "        self.nn_fracture = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280, 7)\n",
    "        )\n",
    "        self.nn_vertebrae = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1280, 7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)['flatten']\n",
    "        return self.nn_fracture(x), self.nn_vertebrae(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        frac, vert = self.forward(x)\n",
    "        return torch.sigmoid(frac), torch.sigmoid(vert)\n",
    "\n",
    "# Predicción usando modelos EfficientNet\n",
    "def predict_effnet(models: List[EffnetModel], ds) -> np.ndarray:\n",
    "    dl_test = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    print(f\"Dataloader size: {len(dl_test)}\")\n",
    "    for m in models:\n",
    "        m.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X in dl_test:\n",
    "            print(f\"Predicting batch {len(predictions) + 1}\")\n",
    "            pred = torch.zeros(len(X), 14).to(DEVICE)\n",
    "            for m in models:\n",
    "                y1, y2 = m.predict(X.to(DEVICE))\n",
    "                pred += torch.cat([y1, y2], dim=1) / len(models)\n",
    "            predictions.append(pred)\n",
    "    return torch.cat(predictions).cpu().numpy()\n",
    "\n",
    "# Calcular predicción final del paciente\n",
    "def patient_prediction(df):\n",
    "    c1c7 = np.average(df[FRAC_COLS].values, axis=0, weights=df[VERT_COLS].values)\n",
    "    pred_patient_overall = 1 - np.prod(1 - c1c7)\n",
    "    return pd.Series(data=np.concatenate([[pred_patient_overall], c1c7]), index=['patient_overall'] + [f'C{i}' for i in range(1, 8)])\n",
    "\n",
    "# Predicción para un paciente individual\n",
    "def predict_single_patient(models: List[EffnetModel], patient_path: str):\n",
    "    dicom_files = glob.glob(f'{patient_path}/*.dcm')\n",
    "    if not dicom_files:\n",
    "        raise FileNotFoundError(f\"No DICOM files found in {patient_path}\")\n",
    "    \n",
    "    slices = [(os.path.basename(patient_path), int(re.search(r'(\\d+)\\.dcm', f).group(1))) for f in dicom_files]\n",
    "    df_patient_slices = pd.DataFrame(slices, columns=['StudyInstanceUID', 'Slice']).sort_values('Slice')\n",
    "\n",
    "    ds_patient = EffnetDataSet(df_patient_slices, patient_path, WEIGHTS)\n",
    "    effnet_pred = predict_effnet(models, ds_patient)\n",
    "\n",
    "    df_effnet_pred = pd.DataFrame(data=effnet_pred, columns=FRAC_COLS + VERT_COLS)\n",
    "    df_patient_pred = pd.concat([df_patient_slices, df_effnet_pred], axis=1)\n",
    "    pred_final = patient_prediction(df_patient_pred)\n",
    "\n",
    "    # Aplicar threshold de 0.6\n",
    "    pred_final[columns_to_transform] = pred_final[columns_to_transform].applymap(lambda x: 1 if x > 0.6 else 0)\n",
    "    return pred_final\n",
    "\n",
    "# Cargar modelos y hacer predicción\n",
    "effnet_models = [load_model(EffnetModel(), name, EFFNET_CHECKPOINTS_PATH).to(DEVICE) for name in MODEL_NAMES]\n",
    "patient_path = 'data/train_images/1.2.826.0.1.3680043.14'\n",
    "df_patient_final = predict_single_patient(effnet_models, patient_path)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_patient_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSci_RSNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
