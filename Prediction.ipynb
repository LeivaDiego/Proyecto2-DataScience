{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "import pydicom as dicom\n",
    "from typing import List\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_v2_s\n",
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_31912\\3392784916.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(os.path.join(path, f'{name}.tph'), map_location=DEVICE)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EffnetModel:\n\tMissing key(s) in state_dict: \"nn_fracture.weight\", \"nn_fracture.bias\", \"nn_vertebrae.weight\", \"nn_vertebrae.bias\". \n\tUnexpected key(s) in state_dict: \"nn_fracture.0.weight\", \"nn_fracture.0.bias\", \"nn_vertebrae.0.weight\", \"nn_vertebrae.0.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 106\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_final\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Cargar modelos y hacer predicción\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m effnet_models \u001b[38;5;241m=\u001b[39m [\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEffnetModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEFFNET_CHECKPOINTS_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m MODEL_NAMES]\n\u001b[0;32m    107\u001b[0m patient_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train_images/1.2.826.0.1.3680043.10001\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    108\u001b[0m df_patient_final \u001b[38;5;241m=\u001b[39m predict_single_patient(effnet_models, patient_path)\n",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model, name, path)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model, name, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[0;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tph\u001b[39m\u001b[38;5;124m'\u001b[39m), map_location\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\maria\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EffnetModel:\n\tMissing key(s) in state_dict: \"nn_fracture.weight\", \"nn_fracture.bias\", \"nn_vertebrae.weight\", \"nn_vertebrae.bias\". \n\tUnexpected key(s) in state_dict: \"nn_fracture.0.weight\", \"nn_fracture.0.bias\", \"nn_vertebrae.0.weight\", \"nn_vertebrae.0.bias\". "
     ]
    }
   ],
   "source": [
    "# Configuración de dispositivo\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 1  # Batch pequeño para procesamiento de un solo paciente\n",
    "\n",
    "# Configuración de modelos y paths\n",
    "WEIGHTS = T.Compose([T.ToTensor(), T.Resize((224, 224))])  # Reemplaza con WEIGHTS.transforms() si es necesario\n",
    "EFFNET_CHECKPOINTS_PATH = \"./models\"  # Reemplaza con la ruta correcta\n",
    "\n",
    "# Lista de nombres de modelos\n",
    "MODEL_NAMES = [f'effnetv2-f{i}' for i in range(5)]\n",
    "FRAC_COLS = [f'C{i}_effnet_frac' for i in range(1, 8)]\n",
    "VERT_COLS = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "columns_to_transform = ['patient_overall'] + [f'C{i}' for i in range(1, 8)]\n",
    "\n",
    "# Función para cargar modelos\n",
    "def load_model(model, name, path='.') -> torch.nn.Module:\n",
    "    data = torch.load(os.path.join(path, f'{name}.tph'), map_location=DEVICE)\n",
    "    model.load_state_dict(data)\n",
    "    return model\n",
    "\n",
    "# Cargar imagen DICOM\n",
    "def load_dicom(path):\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return cv2.cvtColor(data, cv2.COLOR_GRAY2RGB), img\n",
    "\n",
    "# Dataset personalizado para EfficientNet\n",
    "class EffnetDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, path, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        path = os.path.join(self.path, self.df.iloc[i].StudyInstanceUID, f'{self.df.iloc[i].Slice}.dcm')        \n",
    "        img = load_dicom(path)[0]\n",
    "        img = np.transpose(img, (2, 0, 1))  # Convertir a (channels, height, width)\n",
    "        img = self.transforms(torch.as_tensor(img)) if self.transforms else img\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Definición del modelo EfficientNet para predicción\n",
    "class EffnetModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        effnet = efficientnet_v2_s()\n",
    "        self.model = create_feature_extractor(effnet, {'flatten': 'flatten'})\n",
    "        self.nn_fracture = torch.nn.Linear(1280, 7)\n",
    "        self.nn_vertebrae = torch.nn.Linear(1280, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)['flatten']\n",
    "        return self.nn_fracture(x), self.nn_vertebrae(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        frac, vert = self.forward(x)\n",
    "        return torch.sigmoid(frac), torch.sigmoid(vert)\n",
    "\n",
    "# Predicción usando modelos EfficientNet\n",
    "def predict_effnet(models: List[EffnetModel], ds) -> np.ndarray:\n",
    "    dl_test = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    for m in models:\n",
    "        m.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for X in dl_test:\n",
    "            pred = torch.zeros(len(X), 14).to(DEVICE)\n",
    "            for m in models:\n",
    "                y1, y2 = m.predict(X.to(DEVICE))\n",
    "                pred += torch.cat([y1, y2], dim=1) / len(models)\n",
    "            predictions.append(pred)\n",
    "    return torch.cat(predictions).cpu().numpy()\n",
    "\n",
    "# Calcular predicción final del paciente\n",
    "def patient_prediction(df):\n",
    "    c1c7 = np.average(df[FRAC_COLS].values, axis=0, weights=df[VERT_COLS].values)\n",
    "    pred_patient_overall = 1 - np.prod(1 - c1c7)\n",
    "    return pd.Series(data=np.concatenate([[pred_patient_overall], c1c7]), index=['patient_overall'] + [f'C{i}' for i in range(1, 8)])\n",
    "\n",
    "# Predicción para un paciente individual\n",
    "def predict_single_patient(models: List[EffnetModel], patient_path: str):\n",
    "    dicom_files = glob.glob(f'{patient_path}/*.dcm')\n",
    "    slices = [(os.path.basename(patient_path), int(re.search(r'(\\d+)\\.dcm', f).group(1))) for f in dicom_files]\n",
    "    df_patient_slices = pd.DataFrame(slices, columns=['StudyInstanceUID', 'Slice']).sort_values('Slice')\n",
    "\n",
    "    ds_patient = EffnetDataSet(df_patient_slices, patient_path, WEIGHTS)\n",
    "    effnet_pred = predict_effnet(models, ds_patient)\n",
    "\n",
    "    df_effnet_pred = pd.DataFrame(data=effnet_pred, columns=FRAC_COLS + VERT_COLS)\n",
    "    df_patient_pred = pd.concat([df_patient_slices, df_effnet_pred], axis=1)\n",
    "    pred_final = patient_prediction(df_patient_pred)\n",
    "\n",
    "    # Aplicar threshold de 0.6\n",
    "    pred_final[columns_to_transform] = pred_final[columns_to_transform].applymap(lambda x: 1 if x > 0.6 else 0)\n",
    "    return pred_final\n",
    "\n",
    "# Cargar modelos y hacer predicción\n",
    "effnet_models = [load_model(EffnetModel(), name, EFFNET_CHECKPOINTS_PATH).to(DEVICE) for name in MODEL_NAMES]\n",
    "patient_path = '/train_images/1.2.826.0.1.3680043.10001'\n",
    "df_patient_final = predict_single_patient(effnet_models, patient_path)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_patient_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
